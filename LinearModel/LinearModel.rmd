---
title: "Linear MOdel"
author: "erica Sanchez"
date: "10/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
myData = read.csv('RawData.csv')
```



# first model:
SIMS is a function of ARM

```{r}
model1 = lm(SIMS~ARM, data=myData)
summary(model1)
```

predict SIMS for ARM = 88

```{r}
x = data.frame(GRIP=94, ARM=88)
predSIMS = predict.lm(model1, x)
print(predSIMS)
```

prediction interval:

```{r}
predict(model1, x, interval="predict", level=0.95) 
```


# second model SIMS is a function of GRIP

```{r}
model2 = lm(SIMS~GRIP, data=myData)
summary(model2)
```

predict SIMS for GRIP + 94

```{r}
predictSIMS2 = predict.lm(model2, x)
print(predictSIMS2)
```

prediction interval:

```{r}
predict(model2, x, interval="predict") 
```

# Third model SIMS is a function of GRIP + ARM

```{r}
model3 = lm(SIMS~GRIP+ARM, data=myData )
summary(model3)
```

predict SIMS for ARM=88 and GRIP=94 

```{r}
predictSIMS3 = predict.lm(model3, x)
print(predictSIMS3)
```

prediction interval model3

blah blah

comparison between models1 and 3


```{r}
anova(model1, model3)
```


$H_0$: No difference is in the models.  
$H_A$: There is a difference in the models.  

Since the p value is 4.994e-06, we will reject the null hypothesis. There is a difference between model 1 and model 3. The residual sums for squares for model 3 is smaller than model 1. We conclude that model 3 is a better fit than model 1. 





